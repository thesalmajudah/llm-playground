# ðŸ§  BONUS â€“ AI Agents

![Agents Overview](agents.png)

## ðŸš€ Agents, Function Calling & Tool Integration

This module was all about turning LLMs into intelligent *agents* â€” systems that can reason, plan, and interact with tools.

I built an **LLM-powered chatbot** that:

- Takes user questions
- Searches or generates answers
- Writes new entries back into a database using **tool calls** ðŸ’¾

---

## ðŸ’¡ Key Learnings

### ðŸ§  Agents
- LLMs become more than responders â€” they can plan and decide which tools to invoke.

### ðŸ”§ Function Calling
- Structured JSON schema enables the LLM to understand external functions.
- Used **Groq** to power fast LLM function invocation.

### ðŸ”— Tool Use
- Tools were defined as Python functions with metadata.
- LLM decides which tool to use, what arguments to pass, and integrates the result.

### ðŸ” MCP (Model Context Protocol)
- Used `FastMCP` to simulate a lightweight server that LLMs can call over stdio using JSON-RPC.
- Built a custom `MCPClient` and `MCPTools` wrapper to plug external tools into the chat interface.

---

## ðŸ›  Agent Workflow

```mermaid
flowchart TD
    User -->|question| Chatbot
    Chatbot -->|tool call| Tool[get_weather / add_entry]
    Tool -->|result| Chatbot
    Chatbot -->|final response| User
